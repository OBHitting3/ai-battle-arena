# üî• SUPERGROK STRESS TEST PACKAGE
**Project**: Faceless Automation Platform
**Mission**: Break it. Find every weakness. Report everything.

---

## üì¶ WHAT YOU'RE TESTING

A 75%-complete YouTube automation platform that:
- Generates video scripts using AI (Tree of Thought + Beam Search)
- Creates voiceovers with ElevenLabs
- Assembles videos with Remotion + Pexels stock footage
- Generates thumbnails with Adobe Firefly
- Manages projects via FastAPI backend
- Processes payments with Stripe Connect
- Orchestrates everything via Temporal workflows

**Your job**: Find every way this breaks.

---

## üéØ YOUR TESTING OBJECTIVES

### **1. Break the Video Pipeline**
Try to crash Remotion, overflow buffers, cause memory leaks.

### **2. Break the API**
SQL injection, XSS, CSRF, JWT manipulation, DDoS simulation.

### **3. Break the Payment System**
Double-charging, negative amounts, precision errors, webhook replays.

### **4. Break the Workflow**
Race conditions, state corruption, approval timeouts, cancellation bugs.

### **5. Find Performance Bottlenecks**
What breaks at 10 users? 100? 1,000? 10,000?

---

## üöÄ TEST PROMPTS (Use These Exactly)

### **TEST 1: Video Renderer Edge Cases**

```
Test the Remotion video renderer at:
/faceless-automation-platform/src/services/video-assembly/remotion-renderer.ts

Edge cases to test:
1. Video with 0 frames (should error gracefully)
2. Video with 10,000,000 frames (should timeout/fail safely)
3. Script containing only emojis: "üòÄüòÄüòÄüòÄüòÄ"
4. Script with SQL injection: "'; DROP TABLE projects;--"
5. Script with XSS: "<script>alert('hack')</script>"
6. Invalid voiceover path: "/tmp/does-not-exist.mp3"
7. Asset array with 10,000 images
8. Concurrent: Start 100 renders simultaneously
9. Malformed composition: Missing required fields
10. File permission errors: Write to /read-only-dir

For each test:
- Does it crash or handle gracefully?
- What error messages appear?
- Any data corruption?
- Any security issues exposed?

Report all failures with stack traces.
```

---

### **TEST 2: Asset Sourcer Stress Test**

```
Test the Pexels asset sourcer at:
/faceless-automation-platform/src/services/video-assembly/asset-sourcer.ts

Edge cases:
1. Search with empty string: ""
2. Search with 10,000 character string
3. Search with unicode: "Êó•Êú¨Ë™û„ÉÜ„Çπ„Éàüéå"
4. Search with SQL: "'; SELECT * FROM users;--"
5. Request 10,000 assets at once
6. Concurrent: 100 simultaneous searches
7. Invalid API key: "invalid-key-12345"
8. Network timeout simulation
9. Pexels API rate limit (429 error)
10. Disk full during asset download

For each:
- Does it crash or degrade gracefully?
- Are errors logged properly?
- Any resource leaks (memory, file handles)?
- Can you trigger API key exposure in errors?

Report all vulnerabilities.
```

---

### **TEST 3: Thumbnail Generator Attack**

```
Test the Adobe Firefly thumbnail generator at:
/faceless-automation-platform/src/services/video-assembly/thumbnail-generator.ts

Attack vectors:
1. Title with 10,000 characters
2. Title with unicode: "ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ‰∏≠Êñá Êó•Êú¨Ë™û"
3. Title with HTML: "<img src=x onerror=alert(1)>"
4. Negative width/height: -1920x-1080
5. Invalid aspect ratio: "999:1"
6. Concurrent: Generate 1,000 thumbnails
7. Adobe API error responses (401, 403, 429, 500)
8. Network failures mid-generation
9. Disk full during thumbnail save
10. Invalid API key rotation

For each:
- Does error handling work?
- Are API keys logged in errors?
- Any rate limit bypasses possible?
- Can you cause file system corruption?

Report security holes and crashes.
```

---

### **TEST 4: FastAPI Backend Penetration**

```
Test the FastAPI backend at:
/faceless-automation-platform/backend/app/

Attack surfaces:
1. **SQL Injection**:
   - POST /api/projects with title: "'; DROP TABLE users;--"
   - GET /api/projects/{project_id} with id: "1 OR 1=1"

2. **JWT Manipulation**:
   - Expired tokens
   - Modified payload
   - None algorithm attack
   - Token from different user

3. **XSS Injection**:
   - Project title: "<script>alert('XSS')</script>"
   - Description with iframe injection

4. **CSRF Attack**:
   - Cross-origin requests
   - Missing CSRF tokens

5. **DDoS Simulation**:
   - 10,000 login attempts/second
   - 100,000 /health requests
   - Recursive API calls

6. **Input Validation**:
   - Negative IDs
   - Null values
   - Extremely large JSON payloads (>10MB)
   - Malformed JSON

7. **Authentication Bypass**:
   - Access /api/projects without token
   - Use expired tokens
   - Forge tokens

For each attack:
- Did it succeed?
- What information was leaked?
- Any 500 errors with stack traces?
- Can you access other users' data?

Report all successful attacks.
```

---

### **TEST 5: Payment System Exploitation**

```
Test Stripe Connect integration at:
/faceless-automation-platform/backend/app/routers/payments.py

Exploit attempts:
1. **Revenue Calculation Precision**:
   - Amount: $0.01 (expect platform fee calculation)
   - Amount: $999,999,999.99
   - Amount: -$100 (negative charge)
   - Amount with rounding errors: $10.006

2. **Webhook Replay Attack**:
   - Capture webhook payload
   - Replay 1,000 times
   - Can you trigger duplicate credits?

3. **Race Conditions**:
   - Process same payment from 2 threads
   - Concurrent revenue share calculations
   - Simultaneous transfers

4. **Malicious Webhooks**:
   - Invalid Stripe signature
   - Tampered payment amounts
   - Fake payment_intent IDs

5. **Integer Overflow**:
   - Platform fee calculation with MAX_INT
   - Revenue share with very small decimals

6. **Concurrent Transfers**:
   - Start 1,000 transfers simultaneously
   - Do any fail silently?
   - Is double-charging possible?

For each:
- Can you steal money?
- Can you cause incorrect calculations?
- Are there audit logs?
- Can webhooks be replayed?

Report all financial vulnerabilities.
```

---

### **TEST 6: Temporal Workflow Chaos**

```
Test the Temporal content workflow at:
/faceless-automation-platform/src/workflows/content-workflow.ts

Chaos scenarios:
1. **Network Failures**:
   - Kill network mid-workflow
   - Does it recover?
   - Is state preserved?

2. **Activity Timeouts**:
   - Slow down activities artificially
   - Do retries work?
   - Any infinite loops?

3. **Race Conditions**:
   - Start 100 workflows for same project
   - Approve script from 2 different sessions
   - Cancel during critical operations

4. **Signal Timing**:
   - Send approval signal before workflow starts
   - Send signal after timeout
   - Send conflicting signals

5. **Resource Exhaustion**:
   - Start 10,000 workflows
   - Do any starve for resources?
   - Memory leaks over time?

6. **State Corruption**:
   - Modify database while workflow running
   - Delete project mid-workflow
   - Change user permissions during execution

For each:
- Does workflow crash or recover?
- Is state preserved correctly?
- Any data corruption?
- Can you break idempotency?

Report all state management bugs.
```

---

### **TEST 7: Database & Auth Attacks**

```
Test database models and authentication at:
/faceless-automation-platform/backend/app/models.py
/faceless-automation-platform/backend/app/auth.py

Attacks:
1. **Password Attacks**:
   - Empty password: ""
   - Very long password: 10,000 characters
   - Unicode passwords
   - SQL in password field

2. **Email Validation**:
   - Invalid emails: "notanemail"
   - Email with SQL: "admin'; DROP--"
   - Very long emails

3. **Role Escalation**:
   - Can "client" role access admin endpoints?
   - Can you modify your own role?
   - JWT role tampering

4. **Session Management**:
   - Token never expires?
   - Can you use same token from 2 IPs?
   - Logout doesn't invalidate token?

5. **Database Injection**:
   - ORM bypass attempts
   - Raw SQL injection points
   - NoSQL injection if applicable

Report all authentication bypasses.
```

---

### **TEST 8: Load & Performance Testing**

```
Simulate real-world load:

**Scenario 1: Normal Load**
- 100 concurrent users
- 50 projects created/hour
- 200 API calls/second
- Expected: No errors

**Scenario 2: Peak Load**
- 1,000 concurrent users
- 500 projects/hour
- 2,000 API calls/second
- Expected: Some degradation, no crashes

**Scenario 3: Extreme Load**
- 10,000 concurrent users
- 5,000 projects/hour
- 20,000 API calls/second
- Expected: Rate limiting, graceful degradation

For each scenario:
- Response times (p50, p95, p99)
- Error rates
- Memory usage
- CPU usage
- Database connections
- When does it break?

Report performance bottlenecks.
```

---

## üìä REPORTING FORMAT

For each test, provide:

```
TEST: [Name]
STATUS: [PASS/FAIL]
SEVERITY: [Critical/High/Medium/Low]

WHAT HAPPENED:
[Detailed description]

HOW TO REPRODUCE:
1. [Step 1]
2. [Step 2]
...

EXPECTED:
[What should happen]

ACTUAL:
[What actually happened]

ERROR MESSAGES:
[Any errors, stack traces]

SECURITY IMPACT:
[Can this be exploited?]

FIX PRIORITY:
[1-5, 1 being most urgent]
```

---

## üéØ SUCCESS CRITERIA

### **You WIN if you find:**
- SQL injection vulnerability
- Authentication bypass
- Payment calculation error
- Data corruption bug
- Workflow state loss
- Memory leak
- XSS vulnerability
- Rate limit bypass
- Race condition
- Performance bottleneck

### **Platform PASSES if:**
- Zero critical vulnerabilities
- Handles 1,000 concurrent users
- No data corruption under load
- All payments calculate correctly
- Workflows recover from failures
- Errors don't expose secrets

---

## üèÅ DELIVERABLE

Provide a report titled: **SUPERGROK-FINDINGS.md**

Include:
1. Executive summary
2. Critical issues (fix immediately)
3. High-priority issues (fix this week)
4. Medium/Low issues (fix eventually)
5. Performance baseline
6. Recommended improvements

**Expected**: 10-20 issues found
**Best case**: 0 critical, 5 high, 10 medium
**Worst case**: 5+ critical vulnerabilities

---

## üöÄ START TESTING

1. Review all 8 test prompts above
2. Execute each test systematically
3. Document every failure
4. Provide reproduction steps
5. Suggest fixes where possible

**Time estimate**: 2-4 hours of thorough testing
**Output**: SUPERGROK-FINDINGS.md with all results

**GO BREAK EVERYTHING.** üî•
